{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to use our own preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data_processing import create_feables\n",
    "from utils.data_processing import confusion_matrix\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# You should run the ../../data_preprocessing.ipynb notebook to generate the data before running this\n",
    "data = pd.read_csv(\"../../datasets/data.csv\")\n",
    "\n",
    "labels = data.loc[:,'label']\n",
    "features = data.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>stage</th>\n",
       "      <th>home_p_1_overall_rating</th>\n",
       "      <th>away_p_1_overall_rating</th>\n",
       "      <th>home_p_2_overall_rating</th>\n",
       "      <th>away_p_2_overall_rating</th>\n",
       "      <th>home_p_3_overall_rating</th>\n",
       "      <th>away_p_3_overall_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>home_win_percentage</th>\n",
       "      <th>away_defencePressure</th>\n",
       "      <th>away_defenceAggression</th>\n",
       "      <th>away_win_percentage</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>7106</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>81.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213816</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.334586</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "      <td>18398</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>65.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>9829</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6260</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172794</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18371</th>\n",
       "      <td>19619</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348684</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.72</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  season  month  stage  home_p_1_overall_rating  \\\n",
       "6688         7106    2013      3     28                     81.0   \n",
       "17359       18398    2011     10     10                     72.0   \n",
       "9277         9829    2014      2     19                     62.0   \n",
       "6151         6260    2013     12     16                     79.0   \n",
       "18371       19619    2012     11     14                     66.0   \n",
       "\n",
       "       away_p_1_overall_rating  home_p_2_overall_rating  \\\n",
       "6688                      77.0                     75.0   \n",
       "17359                     74.0                     76.0   \n",
       "9277                      74.0                     62.0   \n",
       "6151                      72.0                     76.0   \n",
       "18371                     64.0                     57.0   \n",
       "\n",
       "       away_p_2_overall_rating  home_p_3_overall_rating  \\\n",
       "6688                      66.0                     73.0   \n",
       "17359                     69.0                     74.0   \n",
       "9277                      73.0                     65.0   \n",
       "6151                      70.0                     72.0   \n",
       "18371                     59.0                     62.0   \n",
       "\n",
       "       away_p_3_overall_rating  ...  home_win_percentage  \\\n",
       "6688                      74.0  ...             0.213816   \n",
       "17359                     69.0  ...             0.412281   \n",
       "9277                      73.0  ...             0.421053   \n",
       "6151                      77.0  ...             0.172794   \n",
       "18371                     61.0  ...             0.348684   \n",
       "\n",
       "       away_defencePressure  away_defenceAggression  away_win_percentage  \\\n",
       "6688                   70.0                    70.0             0.334586   \n",
       "17359                  65.0                    30.0             0.447368   \n",
       "9277                   60.0                    70.0             0.118421   \n",
       "6151                   30.0                    30.0             0.352941   \n",
       "18371                  60.0                    70.0             0.467105   \n",
       "\n",
       "       B365H  B365D  B365A   BWH   BWD   BWA  \n",
       "6688    2.00   3.20   4.00  1.91  3.20  4.33  \n",
       "17359   2.05   3.20   3.75  2.00  3.30  3.75  \n",
       "9277    8.50   6.00   1.29  8.50  4.75  1.30  \n",
       "6151    1.91   3.75   3.60  1.90  3.80  3.25  \n",
       "18371   1.83   3.50   4.33  1.72  3.50  4.33  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Splitting the data into train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 0, stratify = labels)\n",
    "\n",
    "# Show some rows of the data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible outcomes 3\n"
     ]
    }
   ],
   "source": [
    "# Match outcome\n",
    "y_train.head()\n",
    "\n",
    "# Number of possible outcomes\n",
    "# 1 = win\n",
    "# 0 = draw\n",
    "# -1 = lose\n",
    "print('Number of possible outcomes', np.unique(y_train.values).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 38\n"
     ]
    }
   ],
   "source": [
    "# Get number of columns by tacking the number of columns in the X_train\n",
    "columns = X_train.shape[1]\n",
    "print('Number of columns:', columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,939\n",
      "Trainable params: 1,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Activation, Flatten, Dense, Concatenate, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=columns, activation='relu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0001), metrics=['accuracy']) # categorical_crossentropy\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13223 samples, validate on 1470 samples\n",
      "Epoch 1/100\n",
      "13223/13223 [==============================] - 1s 42us/step - loss: 0.4860 - accuracy: 0.2888 - val_loss: 0.4860 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.4824 - accuracy: 0.2888 - val_loss: 0.4830 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.4798 - accuracy: 0.2888 - val_loss: 0.4808 - val_accuracy: 0.2857\n",
      "Epoch 4/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.4780 - accuracy: 0.2888 - val_loss: 0.4793 - val_accuracy: 0.2857\n",
      "Epoch 5/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.3527 - accuracy: 0.3662 - val_loss: 0.2184 - val_accuracy: 0.4646\n",
      "Epoch 6/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2199 - accuracy: 0.4586 - val_loss: 0.2182 - val_accuracy: 0.4646\n",
      "Epoch 7/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2156 - accuracy: 0.4578 - val_loss: 0.2194 - val_accuracy: 0.4646\n",
      "Epoch 8/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.2133 - accuracy: 0.4586 - val_loss: 0.2108 - val_accuracy: 0.4646\n",
      "Epoch 9/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2109 - accuracy: 0.4586 - val_loss: 0.2087 - val_accuracy: 0.4646\n",
      "Epoch 10/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2093 - accuracy: 0.4586 - val_loss: 0.2070 - val_accuracy: 0.4646\n",
      "Epoch 11/100\n",
      "13223/13223 [==============================] - 0s 28us/step - loss: 0.2080 - accuracy: 0.4586 - val_loss: 0.2069 - val_accuracy: 0.4646\n",
      "Epoch 12/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2062 - accuracy: 0.4586 - val_loss: 0.2125 - val_accuracy: 0.4646\n",
      "Epoch 13/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2055 - accuracy: 0.4586 - val_loss: 0.2037 - val_accuracy: 0.4646\n",
      "Epoch 14/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2051 - accuracy: 0.4586 - val_loss: 0.2054 - val_accuracy: 0.4646\n",
      "Epoch 15/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2039 - accuracy: 0.4798 - val_loss: 0.2040 - val_accuracy: 0.4810\n",
      "Epoch 16/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2027 - accuracy: 0.5088 - val_loss: 0.2154 - val_accuracy: 0.4850\n",
      "Epoch 17/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2022 - accuracy: 0.5124 - val_loss: 0.2068 - val_accuracy: 0.4905\n",
      "Epoch 18/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2017 - accuracy: 0.5160 - val_loss: 0.2006 - val_accuracy: 0.5034\n",
      "Epoch 19/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2011 - accuracy: 0.5157 - val_loss: 0.2003 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2008 - accuracy: 0.5226 - val_loss: 0.2002 - val_accuracy: 0.5041\n",
      "Epoch 21/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.2001 - accuracy: 0.5232 - val_loss: 0.2050 - val_accuracy: 0.4810\n",
      "Epoch 22/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.2002 - accuracy: 0.5225 - val_loss: 0.2004 - val_accuracy: 0.5061\n",
      "Epoch 23/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1998 - accuracy: 0.5217 - val_loss: 0.1987 - val_accuracy: 0.5170\n",
      "Epoch 24/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1999 - accuracy: 0.5251 - val_loss: 0.2003 - val_accuracy: 0.5136\n",
      "Epoch 25/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1992 - accuracy: 0.5294 - val_loss: 0.1991 - val_accuracy: 0.5204\n",
      "Epoch 26/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1990 - accuracy: 0.5251 - val_loss: 0.1990 - val_accuracy: 0.5231\n",
      "Epoch 27/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1983 - accuracy: 0.5233 - val_loss: 0.1972 - val_accuracy: 0.5265\n",
      "Epoch 28/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1972 - accuracy: 0.5261 - val_loss: 0.1970 - val_accuracy: 0.5231\n",
      "Epoch 29/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1970 - accuracy: 0.5265 - val_loss: 0.1985 - val_accuracy: 0.5177\n",
      "Epoch 30/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.1961 - accuracy: 0.5280 - val_loss: 0.1978 - val_accuracy: 0.5252\n",
      "Epoch 31/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1952 - accuracy: 0.5292 - val_loss: 0.1999 - val_accuracy: 0.4952\n",
      "Epoch 32/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.1959 - accuracy: 0.5253 - val_loss: 0.1961 - val_accuracy: 0.5238\n",
      "Epoch 33/100\n",
      "13223/13223 [==============================] - 0s 29us/step - loss: 0.1953 - accuracy: 0.5307 - val_loss: 0.1957 - val_accuracy: 0.5272\n",
      "Epoch 34/100\n",
      "13223/13223 [==============================] - 0s 30us/step - loss: 0.1957 - accuracy: 0.5311 - val_loss: 0.1961 - val_accuracy: 0.5252\n",
      "Epoch 35/100\n",
      " 1888/13223 [===>..........................] - ETA: 0s - loss: 0.1986 - accuracy: 0.5101"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "categorical = to_categorical(y_train, num_classes=3)\n",
    "history = model.fit(X_train, categorical, batch_size=32, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the most probable prediction\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == y_test).mean()\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.data_processing import build_confusion_matrix\n",
    "\n",
    "# TODO: Remove this and use the commented import instead\n",
    "def build_confusion_matrix(y_true, y_pred):\n",
    "    return pd.DataFrame(confusion_matrix(y_true, y_pred, labels=[2, 1, 0]),\n",
    "                        index=['Home wins (true)', 'Draw (true)', 'Away wins (true)'],\n",
    "                        columns=['Home wins (pred)', 'Draw (pred)', 'Away wins (pred)'])\n",
    "\n",
    "\n",
    "print(\"Neural network confusion matrix: \\n\", build_confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Neural network to Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Train, Calibrate, and Test data sets\n",
    "X_train_calibrate, X_test, y_train_calibrate, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 0, stratify = labels)\n",
    "X_train, X_calibrate, y_train, y_calibrate = train_test_split(X_train_calibrate, y_train_calibrate, test_size = 0.25, random_state = 0, stratify = y_train_calibrate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import train_calibrate_predict\n",
    "\n",
    "# Creating cross validation data splits\n",
    "cv_sets = model_selection.StratifiedShuffleSplit(n_splits = 5, test_size = 0.20, random_state = 5)\n",
    "cv_sets.get_n_splits(X_train, y_train)\n",
    "\n",
    "# Init Random Forest\n",
    "RF_clf = RandomForestClassifier(n_estimators = 200, random_state = 1, class_weight = 'balanced')\n",
    "\n",
    "#Specficying scorer and parameters for grid search\n",
    "feature_len = features.shape[1]\n",
    "scorer = make_scorer(accuracy_score)\n",
    "parameters_RF = {'clf__max_features': ['auto', 'log2'], 'dm_reduce__n_components': np.arange(5, feature_len, int(np.around(feature_len/5)))}\n",
    "\n",
    "#Initializing dimensionality reductions\n",
    "pca = PCA()\n",
    "RF_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random forest accuracy for train set.\".format(RF_clf.__class__.__name__, accuracy_score(y_train, RF_clf.predict(X_train))))\n",
    "print(\"Random forest accuracy for test set\".format(RF_clf.__class__.__name__, accuracy_score(y_test, RF_clf.predict(X_test))))\n",
    "\n",
    "#Grid search, calibrate, and test the classifier\n",
    "calibrated_RF_clf, dm_reduce, train_score, test_score = train_calibrate_predict(clf = RF_clf, dm_reduction = pca, X_train = X_train, y_train = y_train,\n",
    "                                                                  X_calibrate = X_calibrate, y_calibrate = y_calibrate,\n",
    "                                                                  X_test = X_test, y_test = y_test, cv_sets = cv_sets,\n",
    "                                                                  params = parameters_RF, scorer = scorer, jobs = 1, use_grid_search = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = RF_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (rf_predictions == y_test).mean()\n",
    "print(\"Random forest test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random forest confusion matrix: \\n\", build_confusion_matrix(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
